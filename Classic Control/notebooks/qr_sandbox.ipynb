{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Logger\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reload\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'logger'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from logger import Logger\n",
    "from importlib import reload\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, len_state, num_quant, num_actions):\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        self.num_quant = num_quant\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        self.layer1 = nn.Linear(len_state, 256)\n",
    "        self.layer2 = nn.Linear(256, num_actions*num_quant)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        input = torch.Tensor(x)\n",
    "\n",
    "        x = self.layer1(input)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.layer2(x)\n",
    "        return x.view(-1, self.num_actions, self.num_quant)\n",
    "    \n",
    "    def select_action(self, state, eps):\n",
    "        if not isinstance(state, torch.Tensor): state = torch.Tensor([state])    \n",
    "        \n",
    "        action = torch.randint(0, 2, (1,))\n",
    "        if random.random() > eps: action = self.forward(state).mean(2).max(1)[1]\n",
    "        \n",
    "        return int(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_start, eps_end, eps_dec = 0.25, 0.01, 5\n",
    "eps = lambda steps: eps_end + (eps_start - eps_end) * np.exp(-1. * steps / eps_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(sys.modules['rl_utils'])\n",
    "from rl_utils import ReplayMemory, huber\n",
    "\n",
    "env_name = 'MountainCar-v0'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "memory = ReplayMemory(10000)\n",
    "logger = Logger('q-net', fmt={'loss': '.5f'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = Network(len_state=len(env.reset()), num_quant=2, num_actions=env.action_space.n)\n",
    "Ztgt = Network(len_state=len(env.reset()), num_quant=2, num_actions=env.action_space.n)\n",
    "optimizer = optim.Adam(Z.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2500, 0.7500])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_done = 0\n",
    "running_reward = None\n",
    "gamma, batch_size = 0.99, 32 \n",
    "tau = torch.Tensor((2 * np.arange(Z.num_quant) + 1) / (2.0 * Z.num_quant))\n",
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 16\n",
    "np.arange(1./(2 * n), 1, 1/n)\n",
    "np.full(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.47260767,  0.        ], dtype=float32),\n",
       " array([-0.49763566,  0.        ], dtype=float32),\n",
       " array([-0.5476776,  0.       ], dtype=float32),\n",
       " array([-0.5828702,  0.       ], dtype=float32),\n",
       " array([-0.41138878,  0.        ], dtype=float32),\n",
       " array([-0.4389994,  0.       ], dtype=float32),\n",
       " array([-0.49236712,  0.        ], dtype=float32),\n",
       " array([-0.47498092,  0.        ], dtype=float32),\n",
       " array([-0.53460556,  0.        ], dtype=float32),\n",
       " array([-0.42595017,  0.        ], dtype=float32)]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, e = [], []\n",
    "for i in range(10):\n",
    "    temp = copy.deepcopy(env)\n",
    "    s.append(temp.reset(seed = i)[0])\n",
    "    e.append(temp)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(env, action):\n",
    "    s_prime, r, done, trunc, _ = env.step(action)\n",
    "    return [s_prime, r, done, trunc]\n",
    "\n",
    "step_func = np.vectorize(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.920299999999999"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([pow(.99, n) for n in range(3)])\n",
    "(a * [1, 2, 3]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import process_time\n",
    "\n",
    "def testgpu():\n",
    "    if torch.backends.mps.is_available():\n",
    "        mps_device = torch.device(\"mps\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n1, device=mps_device)\n",
    "    y = x + torch.rand(n1, device=mps_device)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with gpu ({n1}): {t1-t0}\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n2, device=mps_device)\n",
    "    y = x + torch.rand(n2, device=mps_device)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with gpu ({n2}): {t1-t0}\")\n",
    "\n",
    "def testcpu():\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n1)\n",
    "    y = x + torch.rand(n1)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with cpu ({n1}): {t1-t0}\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n2)\n",
    "    y = x + torch.rand(n2)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with cpu ({n2}): {t1-t0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time with cpu (10000): 0.0005150000000000432\n",
      "Total time with cpu (100000000): 1.408566999999998\n",
      "Total time with gpu (10000): 0.002881000000002132\n",
      "Total time with gpu (100000000): 0.0014089999999953307\n"
     ]
    }
   ],
   "source": [
    "n1 = 10000\n",
    "n2 = 100000000\n",
    "testcpu()\n",
    "testgpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(2, np.ceil(np.log2(10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Population must be a sequence.  For dicts or sets, use sorted(d).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/random.py:439\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# Sampling without replacement entails tracking either potential\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# selections (the pool) in a list or previous selections in a set.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# too many calls to _randbelow(), making them slower and\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# causing them to eat more entropy than necessary.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(population, _Sequence):\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPopulation must be a sequence.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor dicts or sets, use sorted(d).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    441\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(population)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Population must be a sequence.  For dicts or sets, use sorted(d)."
     ]
    }
   ],
   "source": [
    "random.sample(1000, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0062, -0.2653,  0.2676,  0.2517])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(10, 4)\n",
    "torch.mean(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m Znext \u001b[38;5;241m=\u001b[39m Ztgt(next_states)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     20\u001b[0m Znext_max \u001b[38;5;241m=\u001b[39m Znext[np\u001b[38;5;241m.\u001b[39marange(batch_size), Znext\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m---> 21\u001b[0m Ttheta \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dones) \u001b[38;5;241m*\u001b[39m Znext_max\n\u001b[1;32m     23\u001b[0m diff \u001b[38;5;241m=\u001b[39m Ttheta\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m theta \n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m huber(diff) \u001b[38;5;241m*\u001b[39m (tau \u001b[38;5;241m-\u001b[39m (diff\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())\u001b[38;5;241m.\u001b[39mabs()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for episode in range(501): \n",
    "    sum_reward = 0\n",
    "    state = env.reset()[0]\n",
    "    while True:\n",
    "        steps_done += 1\n",
    "        \n",
    "        action = Z.select_action(torch.Tensor([state]), eps(steps_done))\n",
    "        next_state, reward, done, trunc, _ = env.step(action)\n",
    "        print(state, action, next_state, reward)\n",
    "        \n",
    "        memory.push(state, action, next_state, reward, float(done | trunc))\n",
    "        sum_reward += reward\n",
    "        \n",
    "        if len(memory) < batch_size: break    \n",
    "        states, actions, rewards, next_states, dones = memory.sample(batch_size)\n",
    "        \n",
    "        theta = Z(states)[np.arange(batch_size), actions]\n",
    "        \n",
    "        Znext = Ztgt(next_states).detach()\n",
    "        Znext_max = Znext[np.arange(batch_size), Znext.mean(2).max(1)[1]]\n",
    "        Ttheta = rewards + gamma * (1 - dones) * Znext_max\n",
    "        \n",
    "        diff = Ttheta.t().unsqueeze(-1) - theta \n",
    "        loss = huber(diff) * (tau - (diff.detach() < 0).float()).abs()\n",
    "        loss = loss.mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        state = next_state\n",
    "        \n",
    "        if steps_done % 100 == 0:\n",
    "            Ztgt.load_state_dict(Z.state_dict())\n",
    "            \n",
    "        if done and episode % 50 == 0:\n",
    "            logger.add(episode, steps=steps_done, running_reward=running_reward, loss=loss.data.numpy())\n",
    "            logger.iter_info()\n",
    "            \n",
    "        if (done or trunc): \n",
    "            running_reward = sum_reward  if not running_reward else 0.2 * sum_reward + running_reward*0.8\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3] + []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
